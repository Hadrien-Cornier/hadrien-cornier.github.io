
https://arxiv.org/pdf/2301.10226.pdf


Basically this is akin to poisoning the LLM by introducing a bias in the sampling process towards certain tokens and then detecting it afterwards.

More or less just the question of attribution ie "is this piece of text from my model ?"
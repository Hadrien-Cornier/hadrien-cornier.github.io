#unread
From Wikipedia, the free encyclopedia

In [computing](https://en.wikipedia.org/wiki/Computing "Computing"), **multitasking** is the [concurrent](https://en.wikipedia.org/wiki/Concurrent_computing "Concurrent computing") execution of multiple tasks (also known as [processes](https://en.wikipedia.org/wiki/Process_(computing) "Process (computing)")) over a certain period of time. New tasks can interrupt already started ones before they finish, instead of waiting for them to end. As a result, a computer executes segments of multiple tasks in an interleaved manner, while the tasks share common processing resources such as [central processing units](https://en.wikipedia.org/wiki/Central_processing_unit "Central processing unit") (CPUs) and [main memory](https://en.wikipedia.org/wiki/Main_memory "Main memory"). Multitasking automatically interrupts the running program, saving its state (partial results, memory contents and computer register contents) and loading the saved state of another program and transferring control to it. This "[context switch](https://en.wikipedia.org/wiki/Context_switch "Context switch")" may be initiated at fixed time intervals ([pre-emptive multitasking](https://en.wikipedia.org/wiki/Pre-emptive_multitasking "Pre-emptive multitasking")), or the running program may be coded to signal to the supervisory software when it can be interrupted ([cooperative multitasking](https://en.wikipedia.org/wiki/Cooperative_multitasking "Cooperative multitasking")).

Multitasking does not require [parallel execution](https://en.wikipedia.org/wiki/Parallel_computing "Parallel computing") of multiple tasks at exactly the same time; instead, it allows more than one task to advance over a given period of time.[[1]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-1) Even on [multiprocessor](https://en.wikipedia.org/wiki/Multiprocessor "Multiprocessor") computers, multitasking allows many more tasks to be run than there are CPUs.

Multitasking is a common feature of computer operating systems since at least the 1960s. It allows more efficient use of the computer hardware; when a program is waiting for some external event such as a user input or an [input/output](https://en.wikipedia.org/wiki/Input/output "Input/output") transfer with a peripheral to complete, the central processor can still be used with another program. In a [time-sharing](https://en.wikipedia.org/wiki/Time-sharing "Time-sharing") system, multiple human operators use the same processor as if it was dedicated to their use, while behind the scenes the computer is serving many users by multitasking their individual programs. In [multiprogramming](https://en.wikipedia.org/wiki/Multiprogramming "Multiprogramming") systems, a task runs until it must wait for an external event or until the operating system's [scheduler](https://en.wikipedia.org/wiki/Scheduling_(computing) "Scheduling (computing)") forcibly swaps the running task out of the CPU. [Real-time](https://en.wikipedia.org/wiki/Real-time_computing "Real-time computing") systems such as those designed to control industrial robots, require timely processing; a single processor might be shared between calculations of machine movement, communications, and user interface.[[2]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-2)

Often multitasking operating systems include measures to change the priority of individual tasks, so that important jobs receive more processor time than those considered less significant. Depending on the operating system, a task might be as large as an entire application program, or might be made up of smaller [threads](https://en.wikipedia.org/wiki/Thread_(computing) "Thread (computing)") that carry out portions of the overall program.

A processor intended for use with multitasking operating systems may include special hardware to securely support multiple tasks, such as [memory protection](https://en.wikipedia.org/wiki/Memory_protection "Memory protection"), and [protection rings](https://en.wikipedia.org/wiki/Protection_ring "Protection ring") that ensure the supervisory software cannot be damaged or subverted by user-mode program errors.

The term "multitasking" has become an international term, as the same word is used in many other languages such as German, Italian, Dutch, Romanian, Czech, Danish and Norwegian.

## Multiprogramming

In the early days of computing, [CPU time](https://en.wikipedia.org/wiki/CPU_time "CPU time") was expensive, and [peripherals](https://en.wikipedia.org/wiki/Peripheral "Peripheral") were very slow. When the computer ran a program that needed access to a peripheral, the central processing unit (CPU) would have to stop executing program instructions while the peripheral processed the data. This was usually very inefficient. Multiprogramming is a computing technique that enables multiple programs to be concurrently loaded and executed into a computer's memory, allowing the CPU to switch between them swiftly. This optimizes CPU utilization by keeping it engaged with the execution of tasks, particularly useful when one program is waiting for I/O operations to complete.

The [Bull Gamma 60](https://en.wikipedia.org/wiki/Bull_Gamma_60 "Bull Gamma 60"), initially designed in 1957 and first released in 1960, was the first computer designed with multiprogramming in mind. Its architecture featured a central memory and a Program Distributor feeding up to twenty-five autonomous processing units, and allowing concurrent operation of multiple clusters.

Another such computer was the _[Leo III](https://en.wikipedia.org/wiki/LEO_(computer)#Applications_and_successors "LEO (computer)")_. During [batch processing](https://en.wikipedia.org/wiki/Batch_processing "Batch processing"), several different programs were loaded in the computer memory, and the first one began to run. When the first program reached an instruction waiting for a peripheral, the context of this program was stored away, and the second program in memory was given a chance to run. The process continued until all programs finished running.[[3]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-3)

The use of multiprogramming was enhanced by the arrival of [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory "Virtual memory") and [virtual machine](https://en.wikipedia.org/wiki/Virtual_machine "Virtual machine") technology, which enabled individual programs to make use of memory and operating system resources as if other concurrently running programs were, for all practical purposes, nonexistent.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]

Multiprogramming gives no guarantee that a program will run in a timely manner. Indeed, the first program may very well run for hours without needing access to a peripheral. As there were no users waiting at an interactive terminal, this was no problem: users handed in a deck of punched cards to an operator, and came back a few hours later for printed results. Multiprogramming greatly reduced wait times when multiple batches were being processed.[[4]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-4)[[5]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-5)

## Cooperative multitasking

Main article: [Cooperative multitasking](https://en.wikipedia.org/wiki/Cooperative_multitasking "Cooperative multitasking")

Early multitasking systems used applications that voluntarily ceded time to one another. This approach, which was eventually supported by many computer [operating systems](https://en.wikipedia.org/wiki/Operating_system "Operating system"), is known today as cooperative multitasking. Although it is now rarely used in larger systems except for specific applications such as [CICS](https://en.wikipedia.org/wiki/CICS "CICS") or the [JES2](https://en.wikipedia.org/wiki/JES2 "JES2") subsystem, cooperative multitasking was once the only scheduling scheme employed by [Microsoft Windows](https://en.wikipedia.org/wiki/Microsoft_Windows "Microsoft Windows") and [classic Mac OS](https://en.wikipedia.org/wiki/Classic_Mac_OS "Classic Mac OS") to enable multiple applications to run simultaneously. Cooperative multitasking is still used today on [RISC OS](https://en.wikipedia.org/wiki/RISC_OS "RISC OS") systems.[[6]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-6)

As a cooperatively multitasked system relies on each process regularly giving up time to other processes on the system, one poorly designed program can consume all of the CPU time for itself, either by performing extensive calculations or by [busy waiting](https://en.wikipedia.org/wiki/Busy_wait "Busy wait"); both would cause the whole system to [hang](https://en.wikipedia.org/wiki/Hang_(computing) "Hang (computing)"). In a server environment, this is a hazard that makes the entire environment unacceptably fragile.

## Preemptive multitasking

Main article: [Preemption (computing) § Preemptive multitasking](https://en.wikipedia.org/wiki/Preemption_(computing)#Preemptive_multitasking "Preemption (computing)")

[![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Kubuntu_21.04_%28KDE_Plasma_5%29_-_Virtual_Desktops.png/220px-Kubuntu_21.04_%28KDE_Plasma_5%29_-_Virtual_Desktops.png)](https://en.wikipedia.org/wiki/File:Kubuntu_21.04_(KDE_Plasma_5)_-_Virtual_Desktops.png)

Kubuntu (KDE Plasma 5) four [Virtual desktops](https://en.wikipedia.org/wiki/Virtual_desktop "Virtual desktop") running multiple programs at the same time

Preemptive multitasking allows the computer system to more reliably guarantee to each process a regular "slice" of operating time. It also allows the system to deal rapidly with important external events like incoming data, which might require the immediate attention of one or another process. Operating systems were developed to take advantage of these hardware capabilities and run multiple processes preemptively. Preemptive multitasking was implemented in [the PDP-6 Monitor](https://en.wikipedia.org/wiki/TOPS-10 "TOPS-10") and [Multics](https://en.wikipedia.org/wiki/Multics "Multics") in 1964, in [OS/360 MFT](https://en.wikipedia.org/wiki/OS/360_and_successors#MFT "OS/360 and successors") in 1967, and in [Unix](https://en.wikipedia.org/wiki/Unix "Unix") in 1969, and was available in [some operating systems](https://en.wikipedia.org/wiki/PDP-8#Programming_facilities "PDP-8") for computers as small as DEC's PDP-8; it is a core feature of all [Unix-like](https://en.wikipedia.org/wiki/Unix-like "Unix-like") operating systems, such as [Linux](https://en.wikipedia.org/wiki/Linux "Linux"), [Solaris](https://en.wikipedia.org/wiki/Solaris_(operating_system) "Solaris (operating system)") and [BSD](https://en.wikipedia.org/wiki/Berkeley_Software_Distribution "Berkeley Software Distribution") with its [derivatives](https://en.wikipedia.org/wiki/Comparison_of_BSD_operating_systems "Comparison of BSD operating systems"),[[7]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-7) as well as modern versions of Windows.

At any specific time, processes can be grouped into two categories: those that are waiting for input or output (called "[I/O bound](https://en.wikipedia.org/wiki/I/O_bound "I/O bound")"), and those that are fully utilizing the CPU ("[CPU bound](https://en.wikipedia.org/wiki/CPU_bound "CPU bound")"). In primitive systems, the software would often "[poll](https://en.wikipedia.org/wiki/Polling_(computer_science) "Polling (computer science)")", or "[busywait](https://en.wikipedia.org/wiki/Busy_waiting "Busy waiting")" while waiting for requested input (such as disk, keyboard or network input). During this time, the system was not performing useful work. With the advent of interrupts and preemptive multitasking, I/O bound processes could be "blocked", or put on hold, pending the arrival of the necessary data, allowing other processes to utilize the CPU. As the arrival of the requested data would generate an interrupt, blocked processes could be guaranteed a timely return to execution.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]

The earliest preemptive multitasking OS available to home users was [Sinclair QDOS](https://en.wikipedia.org/wiki/Sinclair_QDOS "Sinclair QDOS") on the [Sinclair QL](https://en.wikipedia.org/wiki/Sinclair_QL "Sinclair QL"), released in 1984, but it was not a big success. Commodore's [Amiga](https://en.wikipedia.org/wiki/Amiga "Amiga"), released the following year, was the first commercially successful home computer to use the technology, and its multimedia abilities make it a clear ancestor of contemporary multitasking personal computers. Microsoft made preemptive multitasking a core feature of their flagship operating system in the early 1990s when developing [Windows NT 3.1](https://en.wikipedia.org/wiki/Windows_NT_3.1 "Windows NT 3.1") and then [Windows 95](https://en.wikipedia.org/wiki/Windows_95 "Windows 95"). In 1988 Apple offered [A/UX](https://en.wikipedia.org/wiki/A/UX "A/UX") as a [UNIX System V](https://en.wikipedia.org/wiki/UNIX_System_V "UNIX System V")-based alternative to the [Classic Mac OS](https://en.wikipedia.org/wiki/Classic_Mac_OS "Classic Mac OS"). In 2001 Apple switched to the [NeXTSTEP](https://en.wikipedia.org/wiki/NeXTSTEP "NeXTSTEP")-influenced [Mac OS X](https://en.wikipedia.org/wiki/Mac_OS_X "Mac OS X").

A similar model is used in [Windows 9x](https://en.wikipedia.org/wiki/Windows_9x "Windows 9x") and the [Windows NT family](https://en.wikipedia.org/wiki/Windows_NT "Windows NT"), where native 32-bit applications are multitasked preemptively.[[8]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-8) 64-bit editions of Windows, both for the [x86-64](https://en.wikipedia.org/wiki/X86-64 "X86-64") and [Itanium](https://en.wikipedia.org/wiki/Itanium "Itanium") architectures, no longer support legacy 16-bit applications, and thus provide preemptive multitasking for all supported applications.

## Real time

Another reason for multitasking was in the design of [real-time computing](https://en.wikipedia.org/wiki/Real-time_computing "Real-time computing") systems, where there are a number of possibly unrelated external activities needed to be controlled by a single processor system. In such systems a hierarchical interrupt system is coupled with process prioritization to ensure that key activities were given a greater share of available [process time](https://en.wikipedia.org/wiki/Process_time "Process time").[[9]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-9)

## Multithreading[[edit](https://en.wikipedia.org/w/index.php?title=Computer_multitasking&action=edit&section=5 "Edit section: Multithreading")]

As multitasking greatly improved the throughput of computers, programmers started to implement applications as sets of cooperating processes (e. g., one process gathering input data, one process processing input data, one process writing out results on disk). This, however, required some tools to allow processes to efficiently exchange data.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]

[Threads](https://en.wikipedia.org/wiki/Thread_(computing) "Thread (computing)") were born from the idea that the most efficient way for cooperating processes to exchange data would be to share their entire memory space. Thus, threads are effectively processes that run in the same memory context and share other resources with their [parent processes](https://en.wikipedia.org/wiki/Parent_process "Parent process"), such as open files. Threads are described as _lightweight processes_ because switching between threads does not involve changing the memory context.[[10]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-10)[[11]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-11)[[12]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-12)

While threads are scheduled preemptively, some operating systems provide a variant to threads, named _[fibers](https://en.wikipedia.org/wiki/Fiber_(computer_science) "Fiber (computer science)")_, that are scheduled cooperatively. On operating systems that do not provide fibers, an application may implement its own fibers using repeated calls to worker functions. Fibers are even more lightweight than threads, and somewhat easier to program with, although they tend to lose some or all of the benefits of threads on [machines with multiple processors](https://en.wikipedia.org/wiki/Multiprocessing "Multiprocessing").[[13]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-13)

Some systems directly support [multithreading in hardware](https://en.wikipedia.org/wiki/Multithreading_(computer_architecture) "Multithreading (computer architecture)").

## Memory protection

Main article: [Memory protection](https://en.wikipedia.org/wiki/Memory_protection "Memory protection")

Essential to any multitasking system is to safely and effectively share access to system resources. Access to memory must be strictly managed to ensure that no process can inadvertently or deliberately read or write to memory locations outside the process's address space. This is done for the purpose of general system stability and data integrity, as well as data security.

In general, memory access management is a responsibility of the operating system kernel, in combination with hardware mechanisms that provide supporting functionalities, such as a [memory management unit](https://en.wikipedia.org/wiki/Memory_management_unit "Memory management unit") (MMU). If a process attempts to access a memory location outside its memory space, the MMU denies the request and signals the kernel to take appropriate actions; this usually results in forcibly terminating the offending process. Depending on the software and kernel design and the specific error in question, the user may receive an access violation error message such as "segmentation fault".

In a well designed and correctly implemented multitasking system, a given process can never directly access memory that belongs to another process. An exception to this rule is in the case of shared memory; for example, in the [System V](https://en.wikipedia.org/wiki/UNIX_System_V "UNIX System V") inter-process communication mechanism the kernel allocates memory to be mutually shared by multiple processes. Such features are often used by database management software such as PostgreSQL.

Inadequate memory protection mechanisms, either due to flaws in their design or poor implementations, allow for security vulnerabilities that may be potentially exploited by malicious software.

## Memory swapping

Use of a [swap file](https://en.wikipedia.org/wiki/Virtual_memory "Virtual memory") or swap partition is a way for the operating system to provide more memory than is physically available by keeping portions of the primary memory in [secondary storage](https://en.wikipedia.org/wiki/Secondary_storage "Secondary storage"). While multitasking and memory swapping are two completely unrelated techniques, they are very often used together, as swapping memory allows more tasks to be loaded at the same time. Typically, a multitasking system allows another process to run when the running process hits a point where it has to wait for some portion of memory to be reloaded from secondary storage.[[14]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-14)

## Programming

Processes that are entirely independent are not much trouble to program in a multitasking environment. Most of the complexity in multitasking systems comes from the need to share computer resources between tasks and to synchronize the operation of co-operating tasks.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]

Various [concurrent computing](https://en.wikipedia.org/wiki/Concurrent_computing "Concurrent computing") techniques are used to avoid potential problems caused by multiple tasks attempting to access the same resource.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]

Bigger systems were sometimes built with a central processor(s) and some number of [I/O processors](https://en.wikipedia.org/wiki/Channel_I/O "Channel I/O"), a kind of [asymmetric multiprocessing](https://en.wikipedia.org/wiki/Asymmetric_multiprocessing "Asymmetric multiprocessing").[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed "Wikipedia:Citation needed")_]

Over the years, multitasking systems have been refined. Modern operating systems generally include detailed mechanisms for prioritizing processes, while [symmetric multiprocessing](https://en.wikipedia.org/wiki/Symmetric_multiprocessing "Symmetric multiprocessing") has introduced new complexities and capabilities.[[15]](https://en.wikipedia.org/wiki/Computer_multitasking#cite_note-15)